<!--
https://ae01.alicdn.com/kf/Haf4d3b0529ba47669bf69c7bfc71a5f1Y.png
机器学习
卷积神经网络学习
神经网络，包含传统BP神经网络、卷积神经网络等
主要介绍卷积神经网络的相关技能点
-->

## 卷积神经网络

> 卷积神经网络

传统神经网络，对于图片识别来说较为困难。  
假设100x100大小的图片，那对应神经网络来说，就有1w个神经元，若隐藏层也有1w个神经元，
则最终有1亿个权值，最终造成计算难度过大，训练时间太长，训练样本过多

故传统的BP神经网络不适合图片识别。而卷积神经网络，引入了**局部感受野**和**权值共享**的概念。  
局部感受野，对应着一个卷积核，或者叫滤波器，比如3x3大小、5x5大小的卷积核

他大大的减少了神经网络需要训练的参数，因为传统的BP神经网络是属于全连接型的，需要对每一个像素进行连接。  
卷积神经网络，则有一个卷积核的范围，每一个样本，共享一个卷积核，内部的权值也是共享的。

即5x5的卷积核，只有25个权值，通过卷积核计算得到一个权值，然后卷积核在矩阵中位移，比如x、y轴位移为1，
则一个100x100的最终得到了96x96的特征图（100-5+1）

在计算卷积的时候，有两种padding方式，一种SAME，对于超出矩阵的部分，会进行补0，而VALID则是舍去。  
卷积的计算很简单，即对应值与对应的权值相乘，然后求和，得到该次卷积的特征值。

卷积提取特征图，然后使用池化，来实现特征提炼，一般使用最大池化。最大池化也有一个类似卷积核的概念，
或者叫滤波器，他会计算当前核内最大值并取为最终的特征。

不同的卷积核会得到不同的特征图，所以一般训练时会使用多个卷积核。  

LeNet5结构  
原图32x32  
1、卷积核5x5、步长1，最终得到28x28的特征图，使用了6个卷积核，故最红为6个特征图。
然后池化，滤波器大小2x2，步长为2，最终得到14x14的特征图。
2、卷积核5x5，步长为1，最终得到10x10的特征图。但是最终有16个特征图。因为对最初的6个特征图，
采用不同的组合方式得到，单个图片内共享权值，但不同的图组合得到新的特征图时，并不共享权值。

深度学习的基础就是神经网络

三层神经结构的感知器