<!--
https://ae01.alicdn.com/kf/Hb3505621d84a4f8cb125c2910c6991d5M.png
消息队列
消息队列学习（一）
常见消息队列如rabbitmq、kafka、rocketmq，及各自优缺点
常见消息队列如rabbitmq、kafka、rocketmq，及各自优缺点
-->

## 消息队列学习

> 常见消息队列如rabbitmq、kafka、rocketmq，及各自优缺点

### 消息队列前言
常见的问题如：为什么使用mq、使用mq的好处或坏处、mq存在什么优缺点  

#### 1、为什么使用mq
一般会涉及到不同的业务场景，但总体来说是可以：**解耦**、**异步**、**削峰**  

1.1、解耦  
业务场景：A系统需要和BCD三个系统进行数据交互，数据交互由调用相关接口实现。
A存在一份数据，若需要被其他系统调用，则需要编写对应的逻辑，一旦某个系统做出修改，
不再需要此分数据，那么就需要修改大量逻辑，系统严重耦合。
* 引入消息队列：A系统产生数据，发送到mq，其他系统只需要负责各自的消费逻辑即可。
一旦引入新数据集，或者是新的系统，或者需求变动，也只需要变动各自的逻辑。
* 当存在一个系统或模块，调用了多个系统或者模块，相互调用之间逻辑复杂。即引入mq作解耦。

1.2、异步
业务场景：A系统接收到写数据的请求，首先再本地写数据，然后分别调用接口再BCD系统中写数据。
花费时间是累加的。逻辑越复杂，请求响应写数据接口越多，整体花费时间越多，基本不可接受。
* 引入消息队列：A系统写完数据后发送剩余请求指令到mq，由对应的消费者来执行剩下的操作，
对于调用者而言，他的指令是已经执行完毕了的。

1.3、削峰
业务场景：每天峰值期间，A系统接收请求每秒5k+，而系统是直接基于mqsql，正常消费速度为每秒2k，
非峰值期间，请求量一般再三位数。故存在峰值期间系统奔溃的危险。
* 引入消息队列：将所有的请求发送到mq，A系统从mq中消费，保证最大速度不超过每秒2k，逐步消费。
虽然会引起数据积压，但整体来说是可接受的，因为A系统是保持全力输出的。

#### 2、消息队列缺点
1、引入消息队列，也就是引入了外部依赖，则系统整体的可用性降低。一旦mq挂了，则整个系统都无法正常运行 。
故如何保证mq的高可用，是一个研究点。 
2、引入消息队列，则存在重复消费、数据丢失、数据传递的有序性等问题。  
如一致性问题，BCD写库操作，当BC成功而D失败的时候，即是一致性问题。

##### 2.1、如何保证消息队列的高可用性  
2.1.1、rabbitmq高可用性
rabbitmq是基于主从（非分布式）做高可用性的，包含三种模式：单机模式、普通集群模式、镜像集群模式。  
> 单机模式，无高可用性，一般即本地启动进行测试，生产不适用

> 普通集群模式，无高可用性

再多台机器上启动多个rabbitmq实例，每台机器启动一个。而开发人员创建的queue，只会放在其中一个mq上。
但是每个实例都会同步queue的元数据（元数据即queue的一些配置信息，可以通过元数据，快速定位queue所在实例）。
消费数据时，如果连接的时非queue实例，则该实例会从queue所在实例拉取数据。

该方案主要时提高吞吐量，并没有实现高可用性，当queue所在系欸但宕机，仍然存在数据全丢失的危险。
该方案主要就是让集群中的多个节点来服务某个queue的读写操作。  
因为若固定连接queue所在实例，则存在单实例性能瓶颈，但使用该方案，就由一定的数据开销，毕竟非queue节点需要拉取queue数据。

> 镜像集群模式，高可用性

在该模式下，你创建的queue会存在于多个实例上，而非单个实例。也就是每一个queue节点有这个queue的完整镜像，
包含queue的全部数据。每次写消息到queue，会将此条消息同步更新到其他实例上。

开启镜像集群模式，在mq后台中指定要求数据同步到所有节点，也可以要求同步到指定数据的节点，再次创建queue的时候，
应用该策略，就会自动将数据同步到所有的相关节点上。

好处很明显。可用性很高，任何一台服务器宕机，都不会有太大影响，因为其他机器也包含了该queue的完整数据，可以到其他机器上消费。  
坏处在于，性能开销大，毕竟要同步所有消息到每个节点，导致网络宽带压力和消耗大。其次，该方案并不属于分布式，无拓展性可言，
因为一旦增加新节点，该节点则需要获取该queue上所有的数据，一旦数据量大道一定量级，单机无法容纳，则会显露出弊端。

2.1.2、kafka高可用性
kafka基本架构认知：是由多个broker组成，每个broker是一个节点。每创建一份topic，这个topic可以划分为多个partition，
每个partition可以存在不同的broker上，每个partition就放一部分数据。
> kafka是天然的分布式消息队列，每一个topic的数据，分散在堕胎机器上。  
> 而rabbitmq并不属于分布式消息队列，而属于传统的消息队列，只不过提供了一些集群和HA（high availability）的机制。
> 因为每一个节点都包含了完整的数据。

kafak在0.8以前，无HA机制，也就是任何一个broker宕机，则该broker上的partition就丢失了。比如创建了一个topic，
并指定其partition数量为3，分别在三台机器上，当第二台机器宕机，则该topic将有1/3的数据会丢失。

在0.8以后，提供了HA机制，也就是replica（复制品）副本机制，每个partition的数据都会同步到其他机器上，
形成自己的多个replica副本。而所有的replica会选举一个leader出来，那么生产者和消费者均会和此leader打交道，
然后其他的replica就是follower。
写的时候，leader会负责把数据同步到所有的follower上，读的时候就直接读leader上的数据即可。而且只能对leader进行操作，
因为要是可以随意读写每个follower，那么就要关心数据一致性问题，系统复杂度会大大提高，故交由leader管控，
kafka会均匀的将一个partition的所有replica分布在不同的机器上，提高容错性。

当某个broker宕机，则该机器上的partition在其他机器上有replica，故不会影响。如果leader也在此台宕机的机器上，
则会从follower从新选举一个新的leader，从而实现高可用性。  
写数据的时候，生产者就写leader，然后leader将数据写入本地磁盘，接着其他follower自己主动从leader pull数据，
一旦所有的follower同步好数据后，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。

##### 2.2、如何保证消息不被重复消费
不被重复消费，即要保证消息消费的幂等性。需要结合具体的业务来看。  
2.2.1、写数据库  
则先根据主键查询一下，如果有该条记录，则不需要插入，直接update即可。  
2.2.2、写入redis  
redis有set集，是天然的幂等性  
2.2.3、非上述场景  
需要让生产者每次发送数据的时候，内部添加唯一id，然后消费者维护一个id池子，一旦出现重复id，即可避免重复消费。

##### 2.3、如何保证消息的可靠性传输  
或者可以理解为如何处理消息的丢失问题。  
2.3.1、rabbitmq丢失数据  
正常流程为：生产者 -> rabbitmq -> 消费者  
2.3.1.1、当生产者丢失数据  
此时可以使用rabbitmq提供的事务功能channel.txSelect，即生产者发送消息，而消息没有被rabbitmq接收，那么生产者会接收异常报错，
此时可以通过channel.txRollback，然后重试发送消息，如果接收到了消息，那么可以提交事务channel.txCommit。但是使用rabbitmq事务机制，
其吞吐量会下降，因为会消耗大部分性能到事务机制上。

故一般为了保证写rabbitmq数据不丢失，可以开启confirm模式，在生产者开启confirm之后，每次写消息都会分配一个唯一id，
如果写入rabbitmq，那么rabbitmq会回复一个ack消息，告诉此条消息接收成功，这个ack包含id信息。

事务机制和confirm机制最大不同在于，事务机制是同步阻塞机制，即提交一个事务后会阻塞直到事务处理出一个结果。
而confirm是异步非阻塞机制，发送此条消息后可以立即发送下一条消息，然后有异步回调你的接口通知此消息已被接收。
故一般会使用confirm机制。

2.3.1.2、当rabbitmq丢失数据  
即数据在mq中丢失了，此时需要开启rabbitmq的持久化，就是消息写入后会持久化到磁盘，即使mq自己宕机，恢复之后也会自动读取之前
存储的数据。

设置持久化方法是，在创建queue的时候，设置为持久化模式，这样就可以保证rabbitmq持久化queue的元数据，
但是不会持久化queue里的数据的。
然后生产者发送消息的时候，设置deliveryMode为2，表示将消息设置为持久化，此时rabbitmq就会将消息持久化到磁盘中去。

即需要同时设置两个持久化才行。但也存在这种情况，即数据还没有来得及写入磁盘，mq就挂了，导致部分数据丢失。
此时可以结合confirm来实现，只有将数据写入到了磁盘，才会返回ack机制，一旦出现上述情况，生产者也可以知晓那些数据没有写入。

2.3.1.3、当消费者丢失数据  
即消费者获取到数据，结果还未处理，消费者进程挂掉了。而rabbitmq则认为你已经消费了，此时数据就丢失了。  

可以采用rabbitmq提供的ack机制，也就是需要消费者主动ack才会确认此条消息被消费完成。如果队列关闭，则自动拒绝，
表示此条消息消费失败，mq可以重新分配此条消息。

##### 2.4、如何保证消息的顺序性  
比如日志的顺序性。从mysql库移到另一个mysql中，其中产生的日志，需要保证顺序性。如增删改一条数据，
则对应着增删改3条日志，这三条日志，推到mq中，那么此三条数据应该保证顺序性，不能变为增改删。  

解决方案：  
拆分多个queue，每个queue一个consumer，那么就会有多个queue，有点麻烦。或者就是一个queue，但是仅对应一个consumer，
然后这个队列用内存队列做排序，然后分发给底层不同的worker处理。

##### 2.5、如何解决消息队列延时及过期失效问题  
即可能存在消息队列满了，数据积压过多。  

2.5.1、消费端出现问题  
导致大量消息在mq中积压，甚至满载的时候。除了紧急修复消费端之外，还可以紧急扩容，比如队列满载的时候，可以建立多个临时队列，
然后写一个consumer脚本，将原队列的数据分发到这些临时队列上，然后把所有的空闲机器部署consumer，分别绑定queue进行消费。
直到数据消费正常，再关闭consumer脚本，并将正常consumer切回线上队列。

2.5.2、mq中的消息过期失效了  
再rabbitmq中是可以设置过期时间的，一旦数据积压且超过了过期时间，则会导致数据大量丢失。  
除了增加consumer端之外，还可以采用批量重导，等数据过期后，过了高峰期，可以重新查询出过期数据，并将其重新推到mq中。


<!--
总结可能会被问到的问题：
1、为什么使用消息队列 - 介绍项目中，消息队列带来的缺点
2、消息队列的使用有没有遇到什么问题 - 介绍项目中，消息队列带来的缺点
3、非项目性的问题：
    3.1、如何保证消息队列的高可用性
    3.2、如何保证消息队列数据的幂等性
    3.3、如何保证消息队列数据的可靠性
    3.4、如何保证消息队列数据的顺序性
    3.5、如何保证消息队列数据的过期、满载等异常情况
-->
